# Tensorflow SavedModel inferencing with NodeJS

This project showcases the differenent features and capabilities of Open Horizon to manage and deploy applications to edge devices.  We will walk through the process of registering a node agent on different edge devices using hzn (Open Horizon) CLI and perform inferencing/object detection by using the TF SavedModel that was trained and generated by tfjs-pipeline https://github.com/playground/tfjs-pipelline.  We will also leverage MMS(Model Management System) to publish new/udpate models to the management hub.  If an agent is registered and subscribed to MMS, it will periodically poll for updates.  If there is an update available, MMS will download the new/updated model and make it available for the agent.  The application running on the agent will pick up load in the new/updated model.  And if for some reason the application is not able to load in the new model due to bad or buggy deployment, the system will roll back and continue running with the current working model.

pre_process.js is script that provides the sub-processes that will help you through the entire process from labeling the dataset to generating the inference graph with a saved model that can be used in your nodejs application for inferencing or object detections.

* Start with your image dataset
* Resize images (depending on your use case, smaller images size speeds up training time)
* Use tool like labelImag, Maximo Visual Inspection & etc. to label and create bounnding boxes for each class type for each image
* Break the dataset into a training set and a testing set (9:1 ratio)
* Covert csv files from xml files of the data set for generating TFRecord
* Generate TRecord
* Train model
* Generate inference graph from trained model 

## Step 1
- Git clone git@github.com:playground/tfjs-pipelline.git
- CD into tfjs-pipeline and run ```npm install```
- Create a directory ```<my_dataset>``` for you image dataset anywhere on your machine

## Step 2
- In tfjs-pipelne directory, resize your images uniformly by runnning

  ```npm run pre_process --task=resize_image --image_dir=<my_dataset> --width=800 --height=600```

## Step 3
- Use one of the tools like lableImg, MVI(Maximo Visual Inspection) or any others to label and create bounding boxes for each of your images in your dataset
- The tool will generate a mapping xml file with the bounding box coordinate for each custom class you have created for your dataset
- Here is an example of what the xml output from labelImg will look like
```
<annotation>
	<folder>images</folder>
	<filename>hardhat1.jpg</filename>
	<path>/Users/jeff/git_repo/sandbox/wu/playbox/ml/TensorFlow/workspace/training_demo/images/hardhat1.jpg</path>
	<source>
		<database>Unknown</database>
	</source>
	<size>
		<width>800</width>
		<height>600</height>
		<depth>3</depth>
	</size>
	<segmented>0</segmented>
	<object>
		<name>hard-hat</name>
		<pose>Unspecified</pose>
		<truncated>0</truncated>
		<difficult>0</difficult>
		<bndbox>
			<xmin>145</xmin>
			<ymin>37</ymin>
			<xmax>453</xmax>
			<ymax>231</ymax>
		</bndbox>
	</object>
</annotation>
```

- Depending on which tool you use to label your dataset, the xml format will vary but the neccessary information are there for converting to cvs in the following steps
- Pre_process.js script currently supports both labelImg and MVI formats conversion
- Now is a good time to create a labelmap.pbtxt file which will be needed for training the model in a later step.  This file should contain the custom classes you have defined for labeling the dataset.  Here is an example of a lablemap.pbtxt file:
```
  item {
    name: "none_of_the_above"
    id: 0
    display_name: "background"
  }
  item {
    id: 1
    name: 'hard-hat'
    display_name: "hardhat"
  }
```

## Step 4 (optional)
- If you would like to partition your dataset into test and train model, run the following command

  ```npm run prec_process --task=partition_dataset --image_dir=<my_dataset_dir>```

## Step 5
- Convert xml to cvs files which are needed by generate_tfrecord.py to generate TFRecord

  ```npm run pre-process --image_dir=<my_dataset_dir> --task=xml_to_csv```     
  ```npm run pre-process --image_dir=<my_dataset_dir> --task=xml_to_csv --origin=maximo```     

## Step 6
- To generate the TFRecord that we can use to train the model, run the following command

  ```npm run pre_process --task=generate_tfrecords --image_dir=<my_dataset_dir>```

## Step 7
- To train model, run the following commmand

  ```npm run pre_process --task=train_model --pipeline_config_path=<my_dataset_dir>/pipeline.config --model_dir=<my_dataset_dir>/training```

## Step 9
- To generate inference graph from trained model, run the following command

  ```npm run pre_process --trained_checkpoint_dir=<my_dataset_dir>/training --pipeline_config_path=<my_dataset_dir>/pipeline.config --output_directory=<my_dataset_dir>/inference_graph --task=export_inference_graph

docker cp  /Users/jeff/Downloads/demo-model/version_2/. pensive_keller:server/data-set/
https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md

docker run -it --cpu-period=100000 --cpu-quota=50000 --rm tfjs-pipeline
docker run -it --memory="6g" --memory-swap="40g" --memory-swappiness="100" --rm tfjs-pipeline
npm run pre_process --task=train_model --pipeline_config_path=/server/data-set/ssd_efficientdet_d0_512x512_coco17_tpu-8.config --model_dir=/server/data-set/training
npm run pre_process --task=build_all --image_dir=/server/data-set --origin=maximo
docker build --ssh github=$HOME/.ssh/id_rsa -t tfjs-pipeline-ubuntu-2104 .

sudo apt-get update && sudo apt-get install -y curl
curl -sL https://deb.nodesource.com/setup_16.x  | sudo bash
sudo apt-get -yq install nodejs
sudo apt-get install fswebcam -y 

### Nvidia
sudo docker run --rm --gpus all nvidia/cuda:10.0-base nvidia-smi
sudo apt-get install -y nvidia-docker2
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)    && curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -    && curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list
curl https://get.docker.com | sh   && sudo systemctl --now enable docker
docker run --gpus all -it --rm tensorflow/tensorflow:latest-gpu
docker run --gpus all --rm nvidia/cuda nvidia-smi

export LD_LIBRARY_PATH=/usr/local/cuda-10.2/targets/aarch64-linux/lib/:$LD_LIBRARY_PATH
locate libcudart.so
sudo updatedb
sudo apt install mlocate -y
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
ls -l /usr/local/cuda/lib64
dpkg -l | grep cudart